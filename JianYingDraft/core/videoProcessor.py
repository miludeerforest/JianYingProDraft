"""
 * @file   : videoProcessor.py
 * @time   : 18:45
 * @date   : 2024/12/19
 * @mail   : 9727005@qq.com
 * @creator: ShanDong Xiedali
 * @company: HiLand & RainyTop
"""
import random
from typing import Dict, Any, Optional, Tuple
from JianYingDraft.core.configManager import AutoMixConfigManager


class VideoProcessor:
    """
    è§†é¢‘é¢„å¤„ç†å™¨
    å®ç°è§†é¢‘çš„é¢„å¤„ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬å»æ‰å‰3ç§’ã€ç”»é¢æ‰©å¤§5%ã€éšæœºè°ƒæ•´å¯¹æ¯”åº¦å’Œäº®åº¦
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è§†é¢‘é¢„å¤„ç†å™¨"""
        self.config_manager = AutoMixConfigManager
    
    def trim_start(self, media_info: Dict[str, Any], duration: Optional[int] = None) -> Dict[str, Any]:
        """
        è®¾ç½®è§†é¢‘å»æ‰å‰å‡ ç§’çš„å‚æ•°
        
        Args:
            media_info: åª’ä½“ä¿¡æ¯å­—å…¸
            duration: å»æ‰çš„æ—¶é•¿ï¼ˆå¾®ç§’ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
            
        Returns:
            Dict[str, Any]: æ›´æ–°åçš„åª’ä½“ä¿¡æ¯
        """
        if duration is None:
            duration = self.config_manager.get_trim_start_duration()
        
        # ç¡®ä¿å»æ‰çš„æ—¶é•¿ä¸è¶…è¿‡è§†é¢‘æ€»æ—¶é•¿
        video_duration = media_info.get('duration', 0)
        if duration >= video_duration:
            print(f"è­¦å‘Šï¼šå»æ‰æ—¶é•¿({duration/1000000:.1f}s)å¤§äºç­‰äºè§†é¢‘æ€»æ—¶é•¿({video_duration/1000000:.1f}s)ï¼Œè®¾ç½®ä¸º0")
            duration = 0
        
        # è®¾ç½®start_in_mediaå‚æ•°
        media_info['start_in_media'] = duration
        
        # æ›´æ–°å®é™…å¯ç”¨æ—¶é•¿
        if 'duration' in media_info:
            media_info['available_duration'] = video_duration - duration
        
        return media_info
    
    def scale_video(self, segment: Dict[str, Any], scale_factor: Optional[float] = None) -> Dict[str, Any]:
        """
        è®¾ç½®è§†é¢‘ç”»é¢ç¼©æ”¾æ¯”ä¾‹
        
        Args:
            segment: è§†é¢‘ç‰‡æ®µå­—å…¸
            scale_factor: ç¼©æ”¾æ¯”ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
            
        Returns:
            Dict[str, Any]: æ›´æ–°åçš„ç‰‡æ®µä¿¡æ¯
        """
        if scale_factor is None:
            scale_factor = self.config_manager.get_video_scale_factor()
        
        # ç¡®ä¿ç¼©æ”¾æ¯”ä¾‹åœ¨åˆç†èŒƒå›´å†…
        if not 0.1 <= scale_factor <= 5.0:
            print(f"è­¦å‘Šï¼šç¼©æ”¾æ¯”ä¾‹({scale_factor})è¶…å‡ºåˆç†èŒƒå›´(0.1-5.0)ï¼Œè®¾ç½®ä¸º1.05")
            scale_factor = 1.05
        
        # è®¾ç½®clip.scaleå±æ€§
        if 'clip' not in segment:
            segment['clip'] = {
                "alpha": 1.0,
                "flip": {"horizontal": False, "vertical": False},
                "rotation": 0.0,
                "scale": {"x": 1.0, "y": 1.0},
                "transform": {"x": 0.0, "y": 0.0}
            }
        
        segment['clip']['scale'] = {"x": scale_factor, "y": scale_factor}
        
        return segment

    def convert_to_vertical_format(self, segment: Dict[str, Any], media_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†è§†é¢‘è½¬æ¢ä¸º9:16ç«–å±æ ¼å¼

        Args:
            segment: è§†é¢‘ç‰‡æ®µå­—å…¸
            media_info: è§†é¢‘åª’ä½“ä¿¡æ¯

        Returns:
            Dict[str, Any]: æ›´æ–°åçš„ç‰‡æ®µä¿¡æ¯
        """
        # è·å–åŸå§‹è§†é¢‘å°ºå¯¸
        original_width = media_info.get('width', 1920)
        original_height = media_info.get('height', 1080)

        # ç›®æ ‡ç«–å±å°ºå¯¸ (9:16)
        target_width = 1080
        target_height = 1920

        # ä¿®å¤ç¼©æ”¾è®¡ç®—ï¼šç›®æ ‡æ˜¯110%å·¦å³ï¼Œè€Œä¸æ˜¯187%
        # å¯¹äºå¸¸è§çš„1920x1080è§†é¢‘è½¬9:16ï¼Œæˆ‘ä»¬ä½¿ç”¨æ›´åˆç†çš„ç¼©æ”¾
        if original_width >= original_height:
            # æ¨ªå±è§†é¢‘ï¼šä»¥é«˜åº¦ä¸ºå‡†ï¼Œé€‚å½“æ”¾å¤§
            base_scale = target_height / original_height * 0.6  # é™ä½åŸºç¡€ç¼©æ”¾
        else:
            # ç«–å±è§†é¢‘ï¼šä»¥å®½åº¦ä¸ºå‡†
            base_scale = target_width / original_width

        # ç¡®ä¿ç¼©æ”¾åœ¨åˆç†èŒƒå›´å†…ï¼ˆ1.0-1.2ä¹‹é—´ï¼‰
        scale_factor = max(1.0, min(1.2, base_scale))

        # ç¡®ä¿clipç»“æ„å­˜åœ¨
        if 'clip' not in segment:
            segment['clip'] = {
                "alpha": 1.0,
                "flip": {"horizontal": False, "vertical": False},
                "rotation": 0.0,
                "scale": {"x": 1.0, "y": 1.0},
                "transform": {"x": 0.0, "y": 0.0}
            }

        # è®¾ç½®ç¼©æ”¾
        segment['clip']['scale'] = {"x": scale_factor, "y": scale_factor}

        # è®¡ç®—å±…ä¸­ä½ç½®
        # ç¼©æ”¾åçš„å°ºå¯¸
        scaled_width = original_width * scale_factor
        scaled_height = original_height * scale_factor

        # è®¡ç®—åç§»é‡ä½¿è§†é¢‘å±…ä¸­
        offset_x = (target_width - scaled_width) / 2
        offset_y = (target_height - scaled_height) / 2

        # è®¾ç½®ä½ç½®åç§»
        segment['clip']['transform'] = {"x": offset_x, "y": offset_y}

        # è®°å½•è½¬æ¢ä¿¡æ¯
        segment['_vertical_conversion'] = {
            'original_size': {'width': original_width, 'height': original_height},
            'target_size': {'width': target_width, 'height': target_height},
            'scale_factor': scale_factor,
            'offset': {'x': offset_x, 'y': offset_y}
        }

        return segment

    def apply_random_flip(self, segment: Dict[str, Any]) -> Dict[str, Any]:
        """
        éšæœºåº”ç”¨é•œåƒç¿»è½¬ï¼ˆé˜²å®¡æ ¸æŠ€æœ¯ï¼‰

        Args:
            segment: è§†é¢‘ç‰‡æ®µå­—å…¸

        Returns:
            Dict[str, Any]: æ›´æ–°åçš„ç‰‡æ®µä¿¡æ¯
        """
        import random

        # è·å–ç¿»è½¬æ¦‚ç‡é…ç½®ï¼ˆå¦‚æœæ˜¯100%åˆ™å¼ºåˆ¶æ‰§è¡Œï¼‰
        flip_probability = self.config_manager.get_flip_probability()

        if flip_probability >= 1.0 or random.random() < flip_probability:
            # ç¡®ä¿clipç»“æ„å­˜åœ¨
            if 'clip' not in segment:
                segment['clip'] = {
                    "alpha": 1.0,
                    "flip": {"horizontal": False, "vertical": False},
                    "rotation": 0.0,
                    "scale": {"x": 1.0, "y": 1.0},
                    "transform": {"x": 0.0, "y": 0.0}
                }

            # åº”ç”¨æ°´å¹³ç¿»è½¬ï¼ˆæœ€æœ‰æ•ˆçš„é˜²å®¡æ ¸æ‰‹æ®µï¼‰
            segment['clip']['flip']['horizontal'] = True
            print(f"  ğŸ”„ åº”ç”¨é•œåƒç¿»è½¬ï¼ˆé˜²å®¡æ ¸ - {'å¼ºåˆ¶æ‰§è¡Œ' if flip_probability >= 1.0 else f'{flip_probability:.1%}æ¦‚ç‡'}ï¼‰")

        return segment

    def apply_random_speed(self, segment: Dict[str, Any]) -> Dict[str, Any]:
        """
        åº”ç”¨éšæœºå˜é€Ÿå¤„ç†ï¼ˆé˜²å®¡æ ¸æŠ€æœ¯ï¼‰

        Args:
            segment: è§†é¢‘ç‰‡æ®µå­—å…¸

        Returns:
            Dict[str, Any]: æ›´æ–°åçš„ç‰‡æ®µä¿¡æ¯
        """
        import random

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å˜é€Ÿå¤„ç†
        if not self.config_manager.is_speed_variation_enabled():
            return segment

        # è·å–å˜é€ŸèŒƒå›´é…ç½®
        speed_range = self.config_manager.get_speed_variation_range()
        min_speed, max_speed = speed_range

        # ç”Ÿæˆéšæœºå˜é€Ÿï¼ˆé¿å…1.0ï¼Œç¡®ä¿æœ‰å˜åŒ–ï¼‰
        speed_options = []
        current = min_speed
        while current <= max_speed:
            if abs(current - 1.0) > 0.05:  # é¿å…æ¥è¿‘1.0çš„é€Ÿåº¦
                speed_options.append(current)
            current += 0.05

        if speed_options:
            speed = random.choice(speed_options)

            # åˆ›å»ºSpeedå¯¹è±¡
            from pyJianYingDraft.segment import Speed
            speed_obj = Speed(speed)

            # æ·»åŠ åˆ°ç‰‡æ®µ
            if 'speed' not in segment:
                segment['speed'] = speed_obj.export_json()
            else:
                segment['speed']['speed'] = speed

            print(f"  âš¡ åº”ç”¨å˜é€Ÿ: {speed:.2f}xï¼ˆé˜²å®¡æ ¸ï¼‰")

        return segment

    def create_blur_background_effect(self, segment: Dict[str, Any], media_info: Dict[str, Any]) -> tuple[Dict[str, Any], Dict[str, Any]]:
        """
        åˆ›å»ºæ¨¡ç³ŠèƒŒæ™¯æ•ˆæœï¼ˆé˜²å®¡æ ¸æŠ€æœ¯ï¼‰

        Args:
            segment: åŸå§‹è§†é¢‘ç‰‡æ®µå­—å…¸
            media_info: åª’ä½“ä¿¡æ¯å­—å…¸

        Returns:
            tuple: (èƒŒæ™¯ç‰‡æ®µ, å‰æ™¯ç‰‡æ®µ)
        """
        import random
        import copy

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ¨¡ç³ŠèƒŒæ™¯
        if not self.config_manager.is_blur_background_enabled():
            return None, segment

        # æ£€æŸ¥æ¦‚ç‡ï¼ˆå¦‚æœæ˜¯100%åˆ™å¼ºåˆ¶æ‰§è¡Œï¼‰
        blur_probability = self.config_manager.get_blur_background_probability()
        if blur_probability < 1.0 and random.random() > blur_probability:
            return None, segment

        print(f"  ğŸŒ«ï¸  åˆ›å»ºæ¨¡ç³ŠèƒŒæ™¯æ•ˆæœï¼ˆé˜²å®¡æ ¸ - {'å¼ºåˆ¶æ‰§è¡Œ' if blur_probability >= 1.0 else f'{blur_probability:.1%}æ¦‚ç‡'}ï¼‰")

        # è·å–é…ç½®å‚æ•°
        foreground_scale = self.config_manager.get_foreground_scale()
        background_scale = self.config_manager.get_background_scale()
        blur_intensity = self.config_manager.get_background_blur_intensity()

        # åˆ›å»ºèƒŒæ™¯ç‰‡æ®µï¼ˆå¤åˆ¶åŸç‰‡æ®µï¼‰
        background_segment = copy.deepcopy(segment)
        background_media = copy.deepcopy(media_info)

        # è®¾ç½®èƒŒæ™¯ç‰‡æ®µå±æ€§
        background_segment['id'] = f"{segment['id']}_background"

        # èƒŒæ™¯ï¼šæ”¾å¤§å¹¶æ¨¡ç³Š
        if 'clip' not in background_segment:
            background_segment['clip'] = {
                "alpha": 1.0,
                "flip": {"horizontal": False, "vertical": False},
                "rotation": 0.0,
                "scale": {"x": 1.0, "y": 1.0},
                "transform": {"x": 0.0, "y": 0.0}
            }

        # è®¾ç½®èƒŒæ™¯ç¼©æ”¾
        background_segment['clip']['scale']['x'] = background_scale
        background_segment['clip']['scale']['y'] = background_scale

        # æ·»åŠ æ¨¡ç³Šæ»¤é•œåˆ°èƒŒæ™¯
        if 'filters' not in background_segment:
            background_segment['filters'] = []

        # åˆ›å»ºæ¨¡ç³Šæ»¤é•œ
        blur_filter = {
            "id": f"blur_filter_{segment['id']}",
            "type": "blur",
            "intensity": blur_intensity,
            "platform": "mobile"
        }
        background_segment['filters'].append(blur_filter)

        # åˆ›å»ºå‰æ™¯ç‰‡æ®µï¼ˆç¼©å°çš„ä¸»è§†é¢‘ï¼‰
        foreground_segment = copy.deepcopy(segment)
        foreground_media = copy.deepcopy(media_info)

        # è®¾ç½®å‰æ™¯ç‰‡æ®µå±æ€§
        foreground_segment['id'] = f"{segment['id']}_foreground"

        # å‰æ™¯ï¼šç¼©å°å¹¶å±…ä¸­
        if 'clip' not in foreground_segment:
            foreground_segment['clip'] = {
                "alpha": 1.0,
                "flip": {"horizontal": False, "vertical": False},
                "rotation": 0.0,
                "scale": {"x": 1.0, "y": 1.0},
                "transform": {"x": 0.0, "y": 0.0}
            }

        # è®¾ç½®å‰æ™¯ç¼©æ”¾
        foreground_segment['clip']['scale']['x'] = foreground_scale
        foreground_segment['clip']['scale']['y'] = foreground_scale

        print(f"    ğŸ“ èƒŒæ™¯æ”¾å¤§: {background_scale:.1f}x, å‰æ™¯ç¼©æ”¾: {foreground_scale:.1f}x")
        print(f"    ğŸŒ«ï¸  æ¨¡ç³Šå¼ºåº¦: {blur_intensity:.1%}")

        return (background_segment, background_media), (foreground_segment, foreground_media)

    def apply_frame_manipulation(self, segment: Dict[str, Any], media_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        åº”ç”¨æŠ½å¸§/è¡¥å¸§å¤„ç†ï¼ˆå®éªŒæ€§é˜²å®¡æ ¸æŠ€æœ¯ï¼‰

        Args:
            segment: è§†é¢‘ç‰‡æ®µå­—å…¸
            media_info: åª’ä½“ä¿¡æ¯å­—å…¸

        Returns:
            Dict[str, Any]: æ›´æ–°åçš„ç‰‡æ®µä¿¡æ¯
        """
        import random

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨æŠ½å¸§/è¡¥å¸§
        if not self.config_manager.is_frame_manipulation_enabled():
            return segment

        # æ£€æŸ¥æ¦‚ç‡ï¼ˆå¦‚æœæ˜¯100%åˆ™å¼ºåˆ¶æ‰§è¡Œï¼‰
        frame_drop_prob = self.config_manager.get_frame_drop_probability()
        if frame_drop_prob < 1.0 and random.random() > frame_drop_prob:
            return segment

        print(f"  ğŸï¸  åº”ç”¨æŠ½å¸§å¤„ç†ï¼ˆå®éªŒæ€§é˜²å®¡æ ¸ - {'å¼ºåˆ¶æ‰§è¡Œ' if frame_drop_prob >= 1.0 else f'{frame_drop_prob:.1%}æ¦‚ç‡'}ï¼‰")

        # è·å–é…ç½®å‚æ•°
        drop_interval = self.config_manager.get_frame_drop_interval()
        max_drops = self.config_manager.get_max_frame_drops_per_segment()

        # è·å–è§†é¢‘æ—¶é•¿ï¼ˆå¾®ç§’ï¼‰
        video_duration = media_info.get('duration', 0)
        duration_seconds = video_duration / 1000000

        if duration_seconds < drop_interval * 2:
            print(f"    âš ï¸  è§†é¢‘æ—¶é•¿è¿‡çŸ­ï¼Œè·³è¿‡æŠ½å¸§å¤„ç†")
            return segment

        # è®¡ç®—å¯èƒ½çš„æŠ½å¸§ç‚¹
        possible_drops = int(duration_seconds / drop_interval)
        actual_drops = min(possible_drops, max_drops)

        if actual_drops <= 0:
            return segment

        # ç”ŸæˆéšæœºæŠ½å¸§ç‚¹ï¼ˆé¿å¼€å¼€å¤´å’Œç»“å°¾ï¼‰
        drop_points = []
        start_time = drop_interval
        end_time = duration_seconds - drop_interval

        for i in range(actual_drops):
            # åœ¨å¯ç”¨æ—¶é—´èŒƒå›´å†…éšæœºé€‰æ‹©æŠ½å¸§ç‚¹
            if start_time < end_time:
                drop_time = random.uniform(start_time, end_time)
                drop_points.append(drop_time)
                # æ›´æ–°ä¸‹ä¸€ä¸ªæŠ½å¸§ç‚¹çš„æœ€å°æ—¶é—´
                start_time = drop_time + drop_interval

        if drop_points:
            # åˆ›å»ºåˆ†å‰²ç‚¹ä¿¡æ¯ï¼ˆè¿™é‡Œåªæ˜¯æ ‡è®°ï¼Œå®é™…åˆ†å‰²éœ€è¦åœ¨æ›´é«˜å±‚å®ç°ï¼‰
            if 'frame_drops' not in segment:
                segment['frame_drops'] = []

            for drop_time in drop_points:
                drop_info = {
                    'time': drop_time,
                    'duration': 0.1,  # æŠ½æ‰0.1ç§’
                    'type': 'frame_drop'
                }
                segment['frame_drops'].append(drop_info)

            print(f"    ğŸï¸  è®¡åˆ’æŠ½å¸§ç‚¹: {len(drop_points)}ä¸ª")
            for i, drop_time in enumerate(drop_points, 1):
                print(f"      {i}. {drop_time:.1f}så¤„æŠ½å¸§0.1s")

        return segment

    def adjust_color_randomly(self, segment: Dict[str, Any]) -> Dict[str, Any]:
        """
        éšæœºè°ƒæ•´è§†é¢‘çš„å¯¹æ¯”åº¦å’Œäº®åº¦
        
        Args:
            segment: è§†é¢‘ç‰‡æ®µå­—å…¸
            
        Returns:
            Dict[str, Any]: æ›´æ–°åçš„ç‰‡æ®µä¿¡æ¯
        """
        # è·å–è‰²å½©è°ƒæ•´èŒƒå›´
        (contrast_min, contrast_max), (brightness_min, brightness_max) = self.config_manager.get_color_adjustment_ranges()
        
        # éšæœºç”Ÿæˆå¯¹æ¯”åº¦å’Œäº®åº¦å€¼
        contrast_value = random.uniform(contrast_min, contrast_max)
        brightness_value = random.uniform(brightness_min, brightness_max)
        
        # å¯ç”¨è‰²å½©è°ƒæ•´åŠŸèƒ½
        segment['enable_color_curves'] = True
        segment['enable_color_wheels'] = True
        segment['enable_adjust'] = True
        
        # è®¾ç½®HDRè®¾ç½®ï¼ˆåŒ…å«äº®åº¦è°ƒæ•´ï¼‰
        if 'hdr_settings' not in segment:
            segment['hdr_settings'] = {"intensity": 1.0, "mode": 1, "nits": 1000}
        
        # è°ƒæ•´äº®åº¦ï¼ˆé€šè¿‡HDR intensityï¼‰
        segment['hdr_settings']['intensity'] = brightness_value
        
        # æ·»åŠ è‰²å½©è°ƒæ•´ä¿¡æ¯åˆ°segmentï¼ˆç”¨äºåç»­å¤„ç†ï¼‰
        segment['_color_adjustments'] = {
            'contrast': contrast_value,
            'brightness': brightness_value,
            'contrast_range': (contrast_min, contrast_max),
            'brightness_range': (brightness_min, brightness_max)
        }
        
        return segment
    
    def process_video_segment(self, video_info: Dict[str, Any], segment_duration: int) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """
        ç»¼åˆå¤„ç†å•ä¸ªè§†é¢‘ç‰‡æ®µ
        
        Args:
            video_info: è§†é¢‘ä¿¡æ¯å­—å…¸
            segment_duration: ç‰‡æ®µæ—¶é•¿ï¼ˆå¾®ç§’ï¼‰
            
        Returns:
            Tuple[Dict[str, Any], Dict[str, Any]]: (å¤„ç†åçš„åª’ä½“ä¿¡æ¯, å¤„ç†åçš„ç‰‡æ®µä¿¡æ¯)
        """
        try:
            # 1. å¤„ç†è§†é¢‘è£å‰ªï¼ˆå»æ‰å‰3ç§’ï¼‰
            processed_media_info = self.trim_start(video_info.copy())
            
            # 2. åˆ›å»ºåŸºç¡€ç‰‡æ®µä¿¡æ¯
            segment_info = {
                "cartoon": False,
                "clip": {
                    "alpha": 1.0,
                    "flip": {"horizontal": False, "vertical": False},
                    "rotation": 0.0,
                    "scale": {"x": 1.0, "y": 1.0},
                    "transform": {"x": 0.0, "y": 0.0}
                },
                "common_keyframes": [],
                "enable_adjust": True,
                "enable_color_curves": True,
                "enable_color_wheels": True,
                "enable_lut": True,
                "enable_smart_color_adjust": False,
                "extra_material_refs": [],
                "group_id": "",
                "hdr_settings": {"intensity": 1.0, "mode": 1, "nits": 1000},
                "intensifies_audio": False,
                "is_placeholder": False,
                "is_tone_modify": False,
                "keyframe_refs": [],
                "last_nonzero_volume": 1.0,
                "material_id": "",
                "render_index": 0,
                "reverse": False,
                "speed": 1.0,
                "template_id": "",
                "template_scene": "default",
                "track_attribute": 0,
                "track_render_index": 0,
                "uniform_scale": {"on": True, "value": 1.0},
                "visible": True,
                "volume": 1.0
            }
            
            # 3. è®¾ç½®æ—¶é—´èŒƒå›´
            start_in_media = processed_media_info.get('start_in_media', 0)
            available_duration = processed_media_info.get('available_duration', segment_duration)
            
            # ç¡®ä¿ç‰‡æ®µæ—¶é•¿ä¸è¶…è¿‡å¯ç”¨æ—¶é•¿
            actual_duration = min(segment_duration, available_duration)
            
            segment_info['source_timerange'] = {
                "duration": actual_duration,
                "start": start_in_media
            }
            segment_info['target_timerange'] = {
                "duration": actual_duration,
                "start": 0
            }
            
            # 4. è½¬æ¢ä¸º9:16ç«–å±æ ¼å¼
            segment_info = self.convert_to_vertical_format(segment_info, processed_media_info)

            # 5. åº”ç”¨ç”»é¢ç¼©æ”¾ï¼ˆä¿®å¤ï¼šç›®æ ‡110%å·¦å³ï¼‰
            # è·å–é¢å¤–çš„ç¼©æ”¾å› å­ï¼ˆé»˜è®¤5%æ”¾å¤§ï¼‰ï¼Œä½†è¦ç¡®ä¿æœ€ç»ˆç»“æœåˆç†
            extra_scale = self.config_manager.get_video_scale_factor()
            if 'clip' in segment_info and 'scale' in segment_info['clip']:
                current_scale = segment_info['clip']['scale']['x']
                # ä¿®å¤ï¼šç¡®ä¿æœ€ç»ˆç¼©æ”¾åœ¨105%-115%èŒƒå›´å†…
                final_scale = current_scale * extra_scale
                # å¦‚æœæœ€ç»ˆç¼©æ”¾è¿‡å¤§ï¼Œè°ƒæ•´åˆ°åˆç†èŒƒå›´
                if final_scale > 1.15:
                    final_scale = 1.1  # ç›®æ ‡110%
                elif final_scale < 1.05:
                    final_scale = 1.05  # æœ€å°105%

                segment_info['clip']['scale'] = {
                    "x": final_scale,
                    "y": final_scale
                }

            # 6. åº”ç”¨éšæœºè‰²å½©è°ƒæ•´
            segment_info = self.adjust_color_randomly(segment_info)

            # 7. åº”ç”¨é˜²å®¡æ ¸æŠ€æœ¯
            segment_info = self.apply_random_flip(segment_info)
            segment_info = self.apply_random_speed(segment_info)
            segment_info = self.apply_frame_manipulation(segment_info, processed_media_info)

            return processed_media_info, segment_info
            
        except Exception as e:
            print(f"å¤„ç†è§†é¢‘ç‰‡æ®µæ—¶å‡ºé”™: {str(e)}")
            # è¿”å›åŸå§‹ä¿¡æ¯ä½œä¸ºå¤‡ç”¨
            return video_info, {}
    
    def batch_process_videos(self, video_list: list, segment_durations: list) -> list:
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘ç‰‡æ®µ
        
        Args:
            video_list: è§†é¢‘ä¿¡æ¯åˆ—è¡¨
            segment_durations: å¯¹åº”çš„ç‰‡æ®µæ—¶é•¿åˆ—è¡¨ï¼ˆå¾®ç§’ï¼‰
            
        Returns:
            list: å¤„ç†ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«(åª’ä½“ä¿¡æ¯, ç‰‡æ®µä¿¡æ¯)
        """
        if len(video_list) != len(segment_durations):
            raise ValueError("è§†é¢‘åˆ—è¡¨å’Œæ—¶é•¿åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…")
        
        results = []
        for i, (video_info, duration) in enumerate(zip(video_list, segment_durations)):
            try:
                media_info, segment_info = self.process_video_segment(video_info, duration)
                results.append({
                    'index': i,
                    'media_info': media_info,
                    'segment_info': segment_info,
                    'success': True,
                    'error': None
                })
            except Exception as e:
                print(f"å¤„ç†ç¬¬{i+1}ä¸ªè§†é¢‘æ—¶å‡ºé”™: {str(e)}")
                results.append({
                    'index': i,
                    'media_info': video_info,
                    'segment_info': {},
                    'success': False,
                    'error': str(e)
                })
        
        return results
    
    def validate_video_info(self, video_info: Dict[str, Any]) -> Tuple[bool, list]:
        """
        éªŒè¯è§†é¢‘ä¿¡æ¯çš„æœ‰æ•ˆæ€§
        
        Args:
            video_info: è§†é¢‘ä¿¡æ¯å­—å…¸
            
        Returns:
            Tuple[bool, list]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        errors = []
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['path', 'duration']
        for field in required_fields:
            if field not in video_info:
                errors.append(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
        
        # æ£€æŸ¥æ—¶é•¿
        duration = video_info.get('duration', 0)
        if duration <= 0:
            errors.append(f"è§†é¢‘æ—¶é•¿æ— æ•ˆ: {duration}")
        
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
        import os
        path = video_info.get('path', '')
        if not os.path.exists(path):
            errors.append(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        return len(errors) == 0, errors
    
    def get_processing_summary(self, processed_results: list) -> Dict[str, Any]:
        """
        è·å–æ‰¹é‡å¤„ç†çš„æ‘˜è¦ä¿¡æ¯
        
        Args:
            processed_results: æ‰¹é‡å¤„ç†ç»“æœåˆ—è¡¨
            
        Returns:
            Dict[str, Any]: æ‘˜è¦ä¿¡æ¯
        """
        total_count = len(processed_results)
        success_count = sum(1 for result in processed_results if result.get('success', False))
        error_count = total_count - success_count
        
        # ç»Ÿè®¡è‰²å½©è°ƒæ•´ä¿¡æ¯
        color_adjustments = []
        for result in processed_results:
            if result.get('success', False):
                segment_info = result.get('segment_info', {})
                if '_color_adjustments' in segment_info:
                    color_adjustments.append(segment_info['_color_adjustments'])
        
        return {
            'total_videos': total_count,
            'success_count': success_count,
            'error_count': error_count,
            'success_rate': success_count / total_count if total_count > 0 else 0,
            'color_adjustments': color_adjustments,
            'average_contrast': sum(adj['contrast'] for adj in color_adjustments) / len(color_adjustments) if color_adjustments else 0,
            'average_brightness': sum(adj['brightness'] for adj in color_adjustments) / len(color_adjustments) if color_adjustments else 0
        }
    
    def print_processing_summary(self, processed_results: list):
        """æ‰“å°å¤„ç†æ‘˜è¦"""
        summary = self.get_processing_summary(processed_results)
        
        print("=== è§†é¢‘é¢„å¤„ç†æ‘˜è¦ ===")
        print(f"æ€»è§†é¢‘æ•°: {summary['total_videos']}")
        print(f"æˆåŠŸå¤„ç†: {summary['success_count']}")
        print(f"å¤„ç†å¤±è´¥: {summary['error_count']}")
        print(f"æˆåŠŸç‡: {summary['success_rate']:.1%}")
        
        if summary['color_adjustments']:
            print(f"å¹³å‡å¯¹æ¯”åº¦è°ƒæ•´: {summary['average_contrast']:.2f}")
            print(f"å¹³å‡äº®åº¦è°ƒæ•´: {summary['average_brightness']:.2f}")
        
        print("=====================")
