"""
 * @file   : autoMixDraft.py
 * @time   : 21:15
 * @date   : 2024/12/19
 * @mail   : 9727005@qq.com
 * @creator: ShanDong Xiedali
 * @company: HiLand & RainyTop
"""
import os
import random
import time
from typing import List, Dict, Any, Optional, Callable
from JianYingDraft.core.draft import Draft
from JianYingDraft.core.materialScanner import MaterialScanner
from JianYingDraft.core.metadataManager import MetadataManager
from JianYingDraft.core.randomEffectEngine import RandomEffectEngine
from JianYingDraft.core.videoProcessor import VideoProcessor
from JianYingDraft.core.dualAudioManager import DualAudioManager
from JianYingDraft.core.srtProcessor import SRTProcessor
from JianYingDraft.core.durationController import DurationController
from JianYingDraft.core.configManager import AutoMixConfigManager


class AutoMixDraft(Draft):
    """
    è‡ªåŠ¨æ··å‰ªå¼•æ“æ ¸å¿ƒç±»
    ç»§æ‰¿Draftç±»ï¼Œé›†æˆæ‰€æœ‰åŠŸèƒ½æ¨¡å—ï¼Œå®ç°å®Œæ•´çš„è‡ªåŠ¨æ··å‰ªæµç¨‹
    """
    
    def __init__(self, name: str = "", config_manager: AutoMixConfigManager = None):
        """
        åˆå§‹åŒ–è‡ªåŠ¨æ··å‰ªå¼•æ“
        
        Args:
            name: è‰ç¨¿åç§°
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        super().__init__(name)
        
        # é…ç½®ç®¡ç†å™¨
        self.config_manager = config_manager or AutoMixConfigManager
        
        # åˆå§‹åŒ–åŠŸèƒ½æ¨¡å—
        self.material_scanner = MaterialScanner()
        self.metadata_manager = MetadataManager()
        self.random_effect_engine = RandomEffectEngine(self.metadata_manager, self.config_manager)
        self.video_processor = VideoProcessor()
        self.dual_audio_manager = DualAudioManager()
        self.srt_processor = SRTProcessor()
        self.duration_controller = DurationController(self.config_manager)
        
        # è¿›åº¦å›è°ƒå‡½æ•°
        self.progress_callback: Optional[Callable[[str, float], None]] = None
        
        # æ··å‰ªç»Ÿè®¡ä¿¡æ¯
        self.mix_statistics = {
            'start_time': 0,
            'end_time': 0,
            'total_materials': 0,
            'selected_materials': 0,
            'applied_filters': 0,
            'applied_transitions': 0,
            'applied_effects': 0,
            'audio_tracks': 0,
            'subtitle_count': 0,
            'final_duration': 0,
            'errors': []
        }
    
    def set_progress_callback(self, callback: Callable[[str, float], None]):
        """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°"""
        self.progress_callback = callback
    
    def _update_progress(self, message: str, progress: float):
        """æ›´æ–°è¿›åº¦"""
        if self.progress_callback:
            self.progress_callback(message, progress)
        else:
            print(f"[{progress:.1%}] {message}")
    
    def auto_mix(self, target_duration: Optional[int] = None,
                product_model: Optional[str] = None,
                narration_audio: Optional[str] = None,
                background_audio: Optional[str] = None,
                subtitle_file: Optional[str] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œè‡ªåŠ¨æ··å‰ªæµç¨‹

        Args:
            target_duration: ç›®æ ‡æ—¶é•¿ï¼ˆå¾®ç§’ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™éšæœºé€‰æ‹©30-40ç§’
            product_model: äº§å“å‹å·ï¼ˆå¦‚A83ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™éšæœºé€‰æ‹©
            narration_audio: è§£è¯´éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰«æåˆ°çš„éŸ³é¢‘ï¼‰
            background_audio: èƒŒæ™¯éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰«æåˆ°çš„ç¯å¢ƒéŸ³æ•ˆï¼‰
            subtitle_file: SRTå­—å¹•æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰«æåˆ°çš„å­—å¹•ï¼‰

        Returns:
            Dict[str, Any]: æ··å‰ªç»“æœä¿¡æ¯
        """
        try:
            self.mix_statistics['start_time'] = time.time()
            self._update_progress("å¼€å§‹è‡ªåŠ¨æ··å‰ªæµç¨‹", 0.0)

            # 1. æ‰«æå¹¶é€‰æ‹©ç´ æ
            self._update_progress("æ‰«æäº§å“ç´ æåº“", 0.1)
            selected_materials = self._scan_and_select_materials(product_model)

            # ä½¿ç”¨æ‰«æåˆ°çš„éŸ³é¢‘å’Œå­—å¹•ï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šçš„è¯ï¼‰
            if narration_audio is None:
                narration_audio = selected_materials.get('narration_audio')
            if background_audio is None:
                background_audio = selected_materials.get('background_audio')
            if subtitle_file is None:
                subtitle_file = selected_materials.get('subtitle_file')
            
            # 2. è®¡ç®—æ—¶é•¿åˆ†é…
            self._update_progress("è®¡ç®—æ—¶é•¿åˆ†é…", 0.3)
            duration_result = self._calculate_durations(selected_materials['videos'], target_duration)

            # 3. å¤„ç†è§†é¢‘ç‰‡æ®µ
            self._update_progress("å¤„ç†è§†é¢‘ç‰‡æ®µ", 0.4)
            processed_videos = self._process_video_segments(selected_materials['videos'], duration_result)
            
            # 5. åº”ç”¨æ»¤é•œå’Œç‰¹æ•ˆ
            self._update_progress("åº”ç”¨æ»¤é•œå’Œç‰¹æ•ˆ", 0.5)
            self._apply_effects_and_filters(processed_videos)
            
            # 6. æ·»åŠ è½¬åœº
            self._update_progress("æ·»åŠ è½¬åœº", 0.6)
            self._add_transitions(processed_videos, duration_result)
            
            # 7. å¤„ç†éŸ³é¢‘è½¨é“
            self._update_progress("å¤„ç†éŸ³é¢‘è½¨é“", 0.7)
            self._process_audio_tracks(narration_audio, background_audio, duration_result['total_duration'])
            
            # 8. æ·»åŠ å­—å¹•
            self._update_progress("æ·»åŠ å­—å¹•", 0.8)
            self._process_subtitles(subtitle_file, duration_result['total_duration'])
            
            # 9. éªŒè¯å’Œä¿å­˜è‰ç¨¿
            self._update_progress("éªŒè¯å’Œä¿å­˜è‰ç¨¿", 0.9)
            self._validate_and_save()
            
            self.mix_statistics['end_time'] = time.time()
            self.mix_statistics['final_duration'] = duration_result['total_duration']
            
            self._update_progress("è‡ªåŠ¨æ··å‰ªå®Œæˆ", 1.0)
            
            return {
                'success': True,
                'draft_path': self._draft_folder,
                'statistics': self.mix_statistics,
                'duration': duration_result['total_duration'],
                'message': 'è‡ªåŠ¨æ··å‰ªæˆåŠŸå®Œæˆ'
            }
            
        except Exception as e:
            error_msg = f"è‡ªåŠ¨æ··å‰ªå¤±è´¥: {str(e)}"
            self.mix_statistics['errors'].append(error_msg)
            self._update_progress(error_msg, -1)
            
            return {
                'success': False,
                'error': error_msg,
                'statistics': self.mix_statistics
            }
    
    def _scan_and_select_materials(self, product_model: Optional[str] = None) -> Dict[str, Any]:
        """æ‰«æå¹¶é€‰æ‹©ç´ æ"""
        try:
            # è·å–ç´ æåº“è·¯å¾„
            material_path = self.config_manager.get_material_path()

            # æ‰«ææŒ‡å®šäº§å“å‹å·çš„ç´ æ
            product_materials = self.material_scanner.scan_product_materials(material_path, product_model)

            if not product_materials['videos']:
                raise ValueError(f"äº§å“å‹å· {product_materials['product_model']} ä¸­æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„è§†é¢‘æ–‡ä»¶")

            # æ™ºèƒ½é€‰æ‹©ç´ æ - æ ¹æ®å­æ–‡ä»¶å¤¹æ•°é‡åŠ¨æ€è°ƒæ•´è§†é¢‘æ•°é‡
            folder_count = len(product_materials['folders'])
            video_count = max(4, folder_count)  # è‡³å°‘4ä¸ªè§†é¢‘ï¼Œæˆ–è€…æ¯ä¸ªæ–‡ä»¶å¤¹ä¸€ä¸ª
            print(f"æ£€æµ‹åˆ° {folder_count} ä¸ªå­æ–‡ä»¶å¤¹ï¼Œå°†é€‰æ‹© {video_count} ä¸ªè§†é¢‘")

            selected_materials = self.material_scanner.select_materials_from_product(
                product_materials,
                video_count=video_count
            )

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.mix_statistics['total_materials'] = len(product_materials['videos'])
            self.mix_statistics['selected_materials'] = len(selected_materials['videos'])
            self.mix_statistics['product_model'] = selected_materials['product_model']

            return selected_materials

        except Exception as e:
            raise ValueError(f"æ‰«æå’Œé€‰æ‹©ç´ æå¤±è´¥: {str(e)}")
    
    def _calculate_durations(self, materials: List[Dict[str, Any]], 
                           target_duration: int) -> Dict[str, Any]:
        """è®¡ç®—æ—¶é•¿åˆ†é…"""
        try:
            # ä½¿ç”¨æ—¶é•¿æ§åˆ¶å™¨è®¡ç®—åˆ†é…
            result = self.duration_controller.optimize_duration_distribution(materials, target_duration)
            
            if not result['success']:
                raise ValueError(f"æ—¶é•¿åˆ†é…å¤±è´¥: {result.get('error', 'Unknown error')}")
            
            return result
            
        except Exception as e:
            raise ValueError(f"è®¡ç®—æ—¶é•¿åˆ†é…å¤±è´¥: {str(e)}")
    
    def _process_video_segments(self, materials: List[Dict[str, Any]], 
                              duration_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å¤„ç†è§†é¢‘ç‰‡æ®µ"""
        try:
            segment_durations = duration_result['segment_durations']
            processed_videos = []
            
            for i, (material, duration) in enumerate(zip(materials, segment_durations)):
                # ä½¿ç”¨è§†é¢‘å¤„ç†å™¨å¤„ç†ç‰‡æ®µ
                media_info, segment_info = self.video_processor.process_video_segment(material, duration)

                # æ·»åŠ è§†é¢‘åˆ°è‰ç¨¿ï¼ˆé™éŸ³å¤„ç†ï¼Œå¹¶åº”ç”¨å¤„ç†åçš„è®¾ç½®ï¼‰
                self.add_media_with_settings(
                    material['path'],
                    start_at_track=0,
                    duration=duration,
                    bgm_mute=True,
                    segment_info=segment_info
                )

                processed_videos.append({
                    'material': material,
                    'media_info': media_info,
                    'segment_info': segment_info,
                    'duration': duration,
                    'index': i
                })
            
            return processed_videos
            
        except Exception as e:
            raise ValueError(f"å¤„ç†è§†é¢‘ç‰‡æ®µå¤±è´¥: {str(e)}")
    
    def _apply_effects_and_filters(self, processed_videos: List[Dict[str, Any]]):
        """åº”ç”¨æ»¤é•œå’Œç‰¹æ•ˆ"""
        try:
            current_time = 0

            for i, video_data in enumerate(processed_videos):
                segment_info = video_data['segment_info']
                segment_duration = video_data['duration']  # ä½¿ç”¨å®é™…åˆ†é…çš„æ—¶é•¿

                print(f"ä¸ºè§†é¢‘ç‰‡æ®µ {i+1} æ·»åŠ ç‰¹æ•ˆ: å¼€å§‹æ—¶é—´={current_time/1000000:.1f}s, æ—¶é•¿={segment_duration/1000000:.1f}s")

                # å¼ºåˆ¶åº”ç”¨æ»¤é•œï¼ˆæé«˜æˆåŠŸç‡ï¼‰
                selected_filter = self.random_effect_engine.select_filter_for_segment(segment_info)
                if not selected_filter:
                    # å¦‚æœéšæœºé€‰æ‹©å¤±è´¥ï¼Œå¼ºåˆ¶é€‰æ‹©ä¸€ä¸ªæ»¤é•œ
                    available_filters = self.metadata_manager.get_available_filters(free_only=True)
                    if available_filters:
                        selected_filter = available_filters[i % len(available_filters)]

                if selected_filter:
                    # ç›´æ¥ä½¿ç”¨æ»¤é•œçš„resource_idå’Œåç§°
                    filter_resource_id = getattr(selected_filter, 'resource_id', '')
                    filter_name = getattr(selected_filter, 'name', '')

                    if filter_resource_id:
                        self.add_effect_with_metadata(
                            resource_id=filter_resource_id,
                            name=filter_name,
                            start=current_time,
                            duration=segment_duration,
                            index=i + 200  # æ»¤é•œä½¿ç”¨ä¸åŒçš„indexèŒƒå›´
                        )
                        self.mix_statistics['applied_filters'] += 1
                        print(f"  âœ… æ·»åŠ æ»¤é•œ: {filter_name}")

                # å¼ºåˆ¶åº”ç”¨ç‰¹æ•ˆï¼ˆæé«˜æˆåŠŸç‡ï¼‰
                selected_effect = self.random_effect_engine.select_effect_for_segment(segment_info)
                if not selected_effect:
                    # å¦‚æœéšæœºé€‰æ‹©å¤±è´¥ï¼Œå¼ºåˆ¶é€‰æ‹©ä¸€ä¸ªç‰¹æ•ˆ
                    available_effects = self.metadata_manager.get_available_effects(free_only=True)
                    if available_effects:
                        selected_effect = available_effects[i % len(available_effects)]

                if selected_effect:
                    # ç›´æ¥ä½¿ç”¨ç‰¹æ•ˆçš„resource_idå’Œåç§°
                    effect_resource_id = getattr(selected_effect, 'resource_id', '')
                    effect_name = getattr(selected_effect, 'name', '')

                    if effect_resource_id:
                        self.add_effect_with_metadata(
                            resource_id=effect_resource_id,
                            name=effect_name,
                            start=current_time,
                            duration=segment_duration,
                            index=i + 100  # ä½¿ç”¨ä¸åŒçš„indexé¿å…å†²çª
                        )
                        self.mix_statistics['applied_effects'] += 1
                        print(f"  âœ… æ·»åŠ ç‰¹æ•ˆ: {effect_name}")

                # ç´¯åŠ æ—¶é—´åˆ°ä¸‹ä¸€ä¸ªç‰‡æ®µ
                current_time += segment_duration

                current_time += segment_duration

        except Exception as e:
            raise ValueError(f"åº”ç”¨æ»¤é•œå’Œç‰¹æ•ˆå¤±è´¥: {str(e)}")
    
    def _add_transitions(self, processed_videos: List[Dict[str, Any]],
                        duration_result: Dict[str, Any]):
        """æ·»åŠ è½¬åœº"""
        try:
            segment_durations = duration_result['segment_durations']
            current_time = 0

            for i in range(len(processed_videos) - 1):
                prev_video = processed_videos[i]
                next_video = processed_videos[i + 1]

                # é€‰æ‹©è½¬åœº
                transition_result = self.random_effect_engine.select_transition_between_segments(
                    prev_video['segment_info'],
                    next_video['segment_info']
                )

                if transition_result:
                    transition_meta, transition_duration = transition_result
                    transition_resource_id = getattr(transition_meta, 'resource_id', '')
                    transition_name = getattr(transition_meta, 'name', '')

                    if transition_resource_id:
                        # è®¡ç®—è½¬åœºå¼€å§‹æ—¶é—´ï¼ˆåœ¨å‰ä¸€ä¸ªç‰‡æ®µç»“æŸæ—¶ï¼‰
                        segment_duration = segment_durations[i]
                        transition_start = current_time + segment_duration - transition_duration // 2

                        # å®é™…æ·»åŠ è½¬åœºåˆ°è‰ç¨¿
                        self.add_transition(
                            transition_name_or_resource_id=transition_resource_id,
                            start=transition_start,
                            duration=transition_duration
                        )
                        self.mix_statistics['applied_transitions'] += 1
                        print(f"  âœ… æ·»åŠ è½¬åœº: {transition_name} (æ—¶é—´: {transition_start/1000000:.1f}s)")

                # ç´¯åŠ æ—¶é—´åˆ°ä¸‹ä¸€ä¸ªç‰‡æ®µ
                current_time += segment_durations[i]

        except Exception as e:
            raise ValueError(f"æ·»åŠ è½¬åœºå¤±è´¥: {str(e)}")
    
    def _process_audio_tracks(self, narration_audio: Optional[str], 
                            background_audio: Optional[str], total_duration: int):
        """å¤„ç†éŸ³é¢‘è½¨é“"""
        try:
            # æ·»åŠ è§£è¯´éŸ³é¢‘
            if narration_audio and os.path.exists(narration_audio):
                narration_volume, _ = self.config_manager.get_audio_volumes()
                self.add_audio_to_specific_track(
                    narration_audio,
                    track_index=0,  # ç¬¬ä¸€ä¸ªéŸ³é¢‘è½¨é“
                    duration=total_duration,
                    volume=narration_volume,
                    track_name="narration"
                )
                self.mix_statistics['audio_tracks'] += 1

            # æ·»åŠ èƒŒæ™¯éŸ³é¢‘
            if background_audio and os.path.exists(background_audio):
                _, background_volume = self.config_manager.get_audio_volumes()
                self.add_audio_to_specific_track(
                    background_audio,
                    track_index=1,  # ç¬¬äºŒä¸ªéŸ³é¢‘è½¨é“
                    duration=total_duration,
                    volume=background_volume,
                    track_name="background"
                )
                self.mix_statistics['audio_tracks'] += 1
            
        except Exception as e:
            raise ValueError(f"å¤„ç†éŸ³é¢‘è½¨é“å¤±è´¥: {str(e)}")

    def add_audio_to_specific_track(self, audio_file: str, track_index: int, duration: int,
                                   volume: float = 1.0, track_name: str = ""):
        """
        æ·»åŠ éŸ³é¢‘åˆ°æŒ‡å®šè½¨é“ - å‚è€ƒdemoç›´æ¥è®¾ç½®éŸ³é‡
        """
        from JianYingDraft.core.mediaFactory import MediaFactory
        from JianYingDraft.core import template

        # åˆ›å»ºéŸ³é¢‘åª’ä½“å¯¹è±¡ï¼Œä¸åœ¨è¿™é‡Œè®¾ç½®éŸ³é‡ï¼Œè€Œæ˜¯åœ¨segmentä¸­è®¾ç½®
        media = MediaFactory.create(audio_file, duration=duration)
        if media is None:
            return

        # å¼ºåˆ¶è®¾ç½®éŸ³é¢‘æ—¶é•¿ä¸ºç›®æ ‡æ—¶é•¿
        media.duration = duration

        # å°†åª’ä½“ä¿¡æ¯æ·»åŠ åˆ°draftçš„ç´ æåº“
        self._Draft__add_media_to_content_materials(media)

        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„éŸ³é¢‘è½¨é“
        all_tracks = self._tracks_in_draft_content
        audio_tracks = [track for track in all_tracks if track["type"] == "audio"]

        # åˆ›å»ºè¶³å¤Ÿçš„éŸ³é¢‘è½¨é“
        while len(audio_tracks) <= track_index:
            new_track = template.get_track()
            new_track["type"] = "audio"
            if track_name:
                new_track["_track_name"] = track_name  # æ·»åŠ è½¨é“æ ‡è¯†
            all_tracks.append(new_track)
            audio_tracks.append(new_track)

        # ä½¿ç”¨æŒ‡å®šçš„éŸ³é¢‘è½¨é“
        target_track = audio_tracks[track_index]

        # è®¾ç½®éŸ³é¢‘ç‰‡æ®µçš„æ—¶é—´èŒƒå›´
        segment_target_timerange = media.segment_data_for_content["target_timerange"]
        segment_target_timerange["start"] = 0
        segment_target_timerange["duration"] = duration  # ç¡®ä¿æ—¶é•¿æ­£ç¡®

        # å¼ºåˆ¶è®¾ç½®source_timerangeï¼Œç¡®ä¿éŸ³é¢‘è¢«æˆªå–åˆ°æ­£ç¡®é•¿åº¦
        if "source_timerange" in media.segment_data_for_content:
            media.segment_data_for_content["source_timerange"]["start"] = 0
            media.segment_data_for_content["source_timerange"]["duration"] = duration
        else:
            media.segment_data_for_content["source_timerange"] = {
                "start": 0,
                "duration": duration
            }

        # å…³é”®ä¿®å¤ï¼šç›´æ¥åœ¨segmentä¸­è®¾ç½®éŸ³é‡ï¼Œå‚è€ƒdemoçš„volume=0.6æ–¹å¼
        media.segment_data_for_content["volume"] = volume
        media.segment_data_for_content["last_nonzero_volume"] = volume

        # ç¡®ä¿éŸ³é‡è®¾ç½®ç”Ÿæ•ˆçš„å…³é”®å±æ€§
        if "extra_material_refs" not in media.segment_data_for_content:
            media.segment_data_for_content["extra_material_refs"] = []

        # åŒæ—¶æ›´æ–°ææ–™æ•°æ®ä¸­çš„æ—¶é•¿
        if "audios" in media.material_data_for_content:
            media.material_data_for_content["audios"]["duration"] = duration

        target_track["segments"].append(media.segment_data_for_content)

        print(f"  âœ… æ·»åŠ éŸ³é¢‘è½¨é“ {track_name}: æ—¶é•¿{duration/1000000:.1f}s, éŸ³é‡{volume:.1%}")

        # å°†åª’ä½“ä¿¡æ¯æ·»åŠ åˆ°draftçš„å…ƒæ•°æ®åº“
        self._Draft__add_media_to_meta_info(media)

    def add_media_with_settings(self, file_path: str, start_at_track: int = 0,
                               duration: int = 0, bgm_mute: bool = False,
                               segment_info: Dict[str, Any] = None):
        """
        æ·»åŠ åª’ä½“å¹¶åº”ç”¨è§†é¢‘å¤„ç†è®¾ç½®ï¼ˆç¼©æ”¾ã€è‰²å½©è°ƒæ•´ç­‰ï¼‰
        """
        from JianYingDraft.core.mediaFactory import MediaFactory

        # åˆ›å»ºåª’ä½“å¯¹è±¡
        media = MediaFactory.create(file_path, duration=duration, bgm_mute=bgm_mute)
        if media is None:
            return

        # åº”ç”¨è§†é¢‘å¤„ç†è®¾ç½® - å‚è€ƒdemoçš„clip_settingsæ–¹å¼
        if segment_info and hasattr(media, 'segment_data_for_content'):
            segment_data = media.segment_data_for_content

            # ç¡®ä¿clipç»“æ„å­˜åœ¨ï¼Œå‚è€ƒdemoçš„Clip_settingsç»“æ„
            if 'clip' not in segment_data:
                segment_data['clip'] = {
                    "alpha": 1.0,
                    "flip": {"horizontal": False, "vertical": False},
                    "rotation": 0.0,
                    "scale": {"x": 1.0, "y": 1.0},
                    "transform": {"x": 0.0, "y": 0.0}
                }

            # å…³é”®ä¿®å¤ï¼šç›´æ¥è®¾ç½®ç¼©æ”¾å€¼ï¼Œç¡®ä¿åœ¨å‰ªæ˜ ç•Œé¢æ˜¾ç¤ºæ­£ç¡®
            if 'clip' in segment_info and 'scale' in segment_info['clip']:
                # ç›´æ¥å¤åˆ¶ç¼©æ”¾è®¾ç½®ï¼Œç¡®ä¿æ•°æ®ç»“æ„å®Œæ•´
                segment_data['clip']['scale']['x'] = segment_info['clip']['scale']['x']
                segment_data['clip']['scale']['y'] = segment_info['clip']['scale']['y']
                print(f"    ğŸ” åº”ç”¨ç¼©æ”¾: {segment_info['clip']['scale']['x']:.2f}x")

            # å…³é”®ä¿®å¤ï¼šç›´æ¥è®¾ç½®ä½ç½®å˜æ¢ï¼Œç¡®ä¿9:16å±…ä¸­å¯¹é½
            if 'clip' in segment_info and 'transform' in segment_info['clip']:
                segment_data['clip']['transform']['x'] = segment_info['clip']['transform']['x']
                segment_data['clip']['transform']['y'] = segment_info['clip']['transform']['y']
                print(f"    ğŸ“ åº”ç”¨ä½ç½®: x={segment_info['clip']['transform']['x']:.1f}, y={segment_info['clip']['transform']['y']:.1f}")

            # åº”ç”¨è‰²å½©è°ƒæ•´
            if '_color_adjustments' in segment_info:
                color_adj = segment_info['_color_adjustments']
                segment_data['enable_adjust'] = True
                segment_data['enable_color_curves'] = True
                segment_data['enable_color_wheels'] = True

                # è®¾ç½®HDRäº®åº¦
                if 'hdr_settings' in segment_info:
                    segment_data['hdr_settings'] = segment_info['hdr_settings'].copy()

                print(f"    ğŸ¨ åº”ç”¨è‰²å½©è°ƒæ•´: å¯¹æ¯”åº¦{color_adj['contrast']:.2f}, äº®åº¦{color_adj['brightness']:.2f}")

            # åº”ç”¨å…¶ä»–è§†é¢‘è®¾ç½®
            for key in ['enable_adjust', 'enable_color_curves', 'enable_color_wheels', 'cartoon']:
                if key in segment_info:
                    segment_data[key] = segment_info[key]

            # ç¡®ä¿segmentæœ‰å¿…è¦çš„å±æ€§
            if 'extra_material_refs' not in segment_data:
                segment_data['extra_material_refs'] = []

        # å°†åª’ä½“ä¿¡æ¯æ·»åŠ åˆ°draftçš„ç´ æåº“
        self._Draft__add_media_to_content_materials(media)

        # å°†åª’ä½“ä¿¡æ¯æ·»åŠ åˆ°draftçš„è½¨é“åº“
        self._Draft__add_media_to_content_tracks(media, start=0)

    def add_effect_with_metadata(self, resource_id: str, name: str, start: int = 0,
                                duration: int = 0, index: int = 0):
        """
        æ·»åŠ å¸¦æ­£ç¡®å…ƒæ•°æ®çš„ç‰¹æ•ˆ
        """
        from JianYingDraft.core.mediaEffect import MediaEffect
        from JianYingDraft.utils import tools
        from JianYingDraft.core import template

        # ç›´æ¥åˆ›å»ºç‰¹æ•ˆåª’ä½“å¯¹è±¡ï¼Œä½¿ç”¨resource_id
        media = MediaEffect(
            effect_name_or_resource_id=resource_id,  # ç›´æ¥ä½¿ç”¨resource_id
            start=start,
            duration=duration
        )

        # æ‰‹åŠ¨ä¿®æ­£åç§°ï¼Œç¡®ä¿æ˜¾ç¤ºä¸­æ–‡åç§°
        if hasattr(media, 'material_data_for_content') and 'video_effects' in media.material_data_for_content:
            effect_data = media.material_data_for_content['video_effects']
            effect_data['name'] = name  # è®¾ç½®ä¸­æ–‡åç§°
            effect_data['resource_id'] = resource_id  # ç¡®ä¿resource_idæ­£ç¡®

        # å°†åª’ä½“ä¿¡æ¯æ·»åŠ åˆ°draftçš„ç´ æåº“
        self._Draft__add_media_to_content_materials(media)

        # å°†åª’ä½“ä¿¡æ¯æ·»åŠ åˆ°draftçš„è½¨é“åº“
        self._Draft__add_media_to_content_tracks(media, start=start)
    
    def _process_subtitles(self, subtitle_file: Optional[str], total_duration: int):
        """å¤„ç†å­—å¹•"""
        try:
            if subtitle_file and os.path.exists(subtitle_file):
                # è§£æSRTæ–‡ä»¶
                subtitles = self.srt_processor.parse_srt_file(subtitle_file)
                
                # ä¿®å¤æ ¼å¼
                fixed_subtitles = self.srt_processor.fix_srt_format(subtitles)
                
                # ä¼˜åŒ–æ—¶é•¿
                optimized_subtitles = self.srt_processor.optimize_subtitle_timing(fixed_subtitles, total_duration)
                
                # æ·»åŠ å­—å¹•åˆ°è‰ç¨¿
                subtitle_count = self.srt_processor.add_subtitles_to_draft(self, optimized_subtitles)
                self.mix_statistics['subtitle_count'] = subtitle_count
            
        except Exception as e:
            raise ValueError(f"å¤„ç†å­—å¹•å¤±è´¥: {str(e)}")
    
    def _validate_and_save(self):
        """éªŒè¯å’Œä¿å­˜è‰ç¨¿"""
        try:
            # éªŒè¯è‰ç¨¿å®Œæ•´æ€§
            draft_duration = self.calc_draft_duration()
            min_duration, max_duration = self.config_manager.get_video_duration_range()

            # æ”¾å®½éªŒè¯èŒƒå›´ï¼Œå…è®¸Â±5ç§’çš„è¯¯å·®
            tolerance = 5000000  # 5ç§’è¯¯å·®
            if not (min_duration - tolerance <= draft_duration <= max_duration + tolerance):
                print(f"è­¦å‘Šï¼šè‰ç¨¿æ—¶é•¿({draft_duration/1000000:.1f}s)ç•¥è¶…å‡ºæ ‡å‡†èŒƒå›´({min_duration/1000000:.1f}s-{max_duration/1000000:.1f}s)ï¼Œä½†åœ¨å¯æ¥å—èŒƒå›´å†…")
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­ä¿å­˜
            
            # ä¿å­˜è‰ç¨¿
            self.save()
            
        except Exception as e:
            raise ValueError(f"éªŒè¯å’Œä¿å­˜è‰ç¨¿å¤±è´¥: {str(e)}")
    
    def batch_generate(self, count: int, **kwargs) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡ç”Ÿæˆå¤šä¸ªæ··å‰ªä½œå“

        Args:
            count: ç”Ÿæˆæ•°é‡
            **kwargs: ä¼ é€’ç»™auto_mixçš„å‚æ•°
                target_duration_range: (min, max) æ—¶é•¿èŒƒå›´å…ƒç»„

        Returns:
            List[Dict[str, Any]]: æ‰¹é‡ç”Ÿæˆç»“æœåˆ—è¡¨
        """
        results = []

        # æå–æ—¶é•¿èŒƒå›´å‚æ•°
        target_duration_range = kwargs.pop('target_duration_range', None)

        for i in range(count):
            try:
                # ä¸ºæ¯ä¸ªè‰ç¨¿ç”Ÿæˆå”¯ä¸€åç§°
                timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime())
                draft_name = f"AutoMix_{timestamp}_{i+1:03d}"

                # åˆ›å»ºæ–°çš„AutoMixDraftå®ä¾‹
                auto_draft = AutoMixDraft(draft_name, self.config_manager)
                auto_draft.set_progress_callback(self.progress_callback)

                # è®¾ç½®éšæœºæ—¶é•¿ï¼ˆå¦‚æœæä¾›äº†èŒƒå›´ï¼‰
                current_kwargs = kwargs.copy()
                if target_duration_range:
                    import random
                    min_duration, max_duration = target_duration_range
                    current_kwargs['target_duration'] = random.randint(min_duration, max_duration)

                # æ‰§è¡Œè‡ªåŠ¨æ··å‰ª
                result = auto_draft.auto_mix(**current_kwargs)
                result['batch_index'] = i + 1
                result['draft_name'] = draft_name

                results.append(result)

            except Exception as e:
                error_result = {
                    'success': False,
                    'batch_index': i + 1,
                    'draft_name': f"AutoMix_Error_{i+1:03d}",
                    'error': str(e)
                }
                results.append(error_result)

        return results
    
    def get_mix_statistics(self) -> Dict[str, Any]:
        """è·å–æ··å‰ªç»Ÿè®¡ä¿¡æ¯"""
        stats = self.mix_statistics.copy()
        
        if stats['end_time'] > 0:
            stats['processing_time'] = stats['end_time'] - stats['start_time']
        
        return stats
    
    def print_mix_summary(self):
        """æ‰“å°æ··å‰ªæ‘˜è¦"""
        stats = self.get_mix_statistics()
        
        print("=== è‡ªåŠ¨æ··å‰ªæ‘˜è¦ ===")
        print(f"å¤„ç†æ—¶é—´: {stats.get('processing_time', 0):.1f}ç§’")
        print(f"æ€»ç´ ææ•°: {stats['total_materials']}")
        print(f"é€‰æ‹©ç´ ææ•°: {stats['selected_materials']}")
        print(f"åº”ç”¨æ»¤é•œæ•°: {stats['applied_filters']}")
        print(f"åº”ç”¨è½¬åœºæ•°: {stats['applied_transitions']}")
        print(f"åº”ç”¨ç‰¹æ•ˆæ•°: {stats['applied_effects']}")
        print(f"éŸ³é¢‘è½¨é“æ•°: {stats['audio_tracks']}")
        print(f"å­—å¹•æ•°é‡: {stats['subtitle_count']}")
        print(f"æœ€ç»ˆæ—¶é•¿: {stats['final_duration']/1000000:.1f}ç§’")
        
        if stats['errors']:
            print(f"é”™è¯¯æ•°é‡: {len(stats['errors'])}")
            for error in stats['errors']:
                print(f"  - {error}")
        
        print("===================")
